{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15166, 2382) (8970, 2382)\n",
      "(24136, 2382)\n"
     ]
    }
   ],
   "source": [
    "# Load Benign and Malware Dataset\n",
    "benign_dataset = pd.read_csv(\"../data/benign.csv\")\n",
    "malware_dataset = pd.read_csv(\"../data/malware.csv\")\n",
    "\n",
    "print(benign_dataset.shape, malware_dataset.shape)\n",
    "\n",
    "# Add Ground Truth Column\n",
    "benign_dataset[\"ground_truth\"] = 0\n",
    "malware_dataset[\"ground_truth\"] = 1\n",
    "\n",
    "# Combine the Two Datasets Shuffling the Rows\n",
    "combined_dataset = pd.concat([benign_dataset, malware_dataset], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "combined_dataset.drop(combined_dataset.columns[0], axis=1, inplace=True)\n",
    "print(combined_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2372</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>2376</th>\n",
       "      <th>2377</th>\n",
       "      <th>2378</th>\n",
       "      <th>2379</th>\n",
       "      <th>2380</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.658894</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.176794</td>\n",
       "      <td>0.028287</td>\n",
       "      <td>0.022401</td>\n",
       "      <td>0.016022</td>\n",
       "      <td>0.017895</td>\n",
       "      <td>0.010846</td>\n",
       "      <td>0.022094</td>\n",
       "      <td>0.009408</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.443070</td>\n",
       "      <td>0.013716</td>\n",
       "      <td>0.009648</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.009137</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.302648</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.344308</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>0.010138</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2382 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.658894  0.006651  0.006222  0.005062  0.004886  0.004337  0.004310   \n",
       "1  0.176794  0.028287  0.022401  0.016022  0.017895  0.010846  0.022094   \n",
       "2  0.443070  0.013716  0.009648  0.007923  0.007454  0.004515  0.009137   \n",
       "3  0.302648  0.013870  0.010625  0.004711  0.005253  0.002154  0.005370   \n",
       "4  0.344308  0.033575  0.015625  0.006789  0.010138  0.005487  0.008278   \n",
       "\n",
       "          7         8         9  ...  2372  2373  2374  2375    2376  2377  \\\n",
       "0  0.004201  0.004017  0.003433  ...   0.0   0.0   0.0   8.0  8192.0   0.0   \n",
       "1  0.009408  0.008462  0.006019  ...   0.0   0.0   0.0   8.0  8192.0   0.0   \n",
       "2  0.003791  0.006070  0.003834  ...   0.0   0.0   0.0   0.0     0.0   0.0   \n",
       "3  0.003102  0.002382  0.001039  ...   0.0   0.0   0.0   8.0  8192.0   0.0   \n",
       "4  0.005580  0.007906  0.003720  ...   0.0   0.0   0.0   8.0  8192.0   0.0   \n",
       "\n",
       "   2378  2379    2380  ground_truth  \n",
       "0   0.0  72.0  8200.0             0  \n",
       "1   0.0  72.0  8200.0             0  \n",
       "2   0.0  72.0  8192.0             0  \n",
       "3   0.0  72.0  8200.0             0  \n",
       "4   0.0  72.0  8200.0             0  \n",
       "\n",
       "[5 rows x 2382 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24136, 2381) (24136,)\n",
      "(19308, 2381) (4828, 2381) (19308,) (4828,)\n"
     ]
    }
   ],
   "source": [
    "X = combined_dataset.drop(\"ground_truth\", axis=1)\n",
    "y = combined_dataset[\"ground_truth\"]\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, InputLayer\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "\n",
    "    feature_size = 2381\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(1, feature_size)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1500, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy', AUC(), Precision()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/csce/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2381</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,573,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,501</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2381\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1500\u001b[0m)        │     \u001b[38;5;34m3,573,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1500\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │         \u001b[38;5;34m1,501\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,574,501</span> (13.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,574,501\u001b[0m (13.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,574,501</span> (13.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,574,501\u001b[0m (13.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "mms = StandardScaler()\n",
    "X_train = mms.fit_transform(X_train)\n",
    "\n",
    "X_train = np.reshape(X_train, (-1, 1, 2381))\n",
    "y_train = np.reshape(y_train, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 206ms/step - accuracy: 0.9382 - auc_3: 0.9792 - loss: 0.1750 - precision_3: 0.8844 - val_accuracy: 0.9925 - val_auc_3: 0.9973 - val_loss: 0.0390 - val_precision_3: 0.9911\n",
      "Epoch 2/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 205ms/step - accuracy: 0.9951 - auc_3: 0.9985 - loss: 0.0220 - precision_3: 0.9938 - val_accuracy: 0.9946 - val_auc_3: 0.9981 - val_loss: 0.0307 - val_precision_3: 0.9932\n",
      "Epoch 3/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 205ms/step - accuracy: 0.9974 - auc_3: 0.9991 - loss: 0.0184 - precision_3: 0.9966 - val_accuracy: 0.9948 - val_auc_3: 0.9975 - val_loss: 0.0320 - val_precision_3: 0.9939\n",
      "Epoch 4/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 218ms/step - accuracy: 0.9985 - auc_3: 0.9995 - loss: 0.0091 - precision_3: 0.9984 - val_accuracy: 0.9948 - val_auc_3: 0.9975 - val_loss: 0.0313 - val_precision_3: 0.9939\n",
      "Epoch 5/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 204ms/step - accuracy: 0.9988 - auc_3: 0.9997 - loss: 0.0072 - precision_3: 0.9983 - val_accuracy: 0.9953 - val_auc_3: 0.9977 - val_loss: 0.0288 - val_precision_3: 0.9945\n",
      "Epoch 6/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 203ms/step - accuracy: 0.9985 - auc_3: 0.9998 - loss: 0.0086 - precision_3: 0.9978 - val_accuracy: 0.9959 - val_auc_3: 0.9981 - val_loss: 0.0268 - val_precision_3: 0.9952\n",
      "Epoch 7/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 223ms/step - accuracy: 0.9987 - auc_3: 0.9995 - loss: 0.0077 - precision_3: 0.9988 - val_accuracy: 0.9964 - val_auc_3: 0.9983 - val_loss: 0.0247 - val_precision_3: 0.9966\n",
      "Epoch 8/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 214ms/step - accuracy: 0.9993 - auc_3: 0.9999 - loss: 0.0038 - precision_3: 0.9997 - val_accuracy: 0.9964 - val_auc_3: 0.9981 - val_loss: 0.0263 - val_precision_3: 0.9966\n",
      "Epoch 9/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 212ms/step - accuracy: 0.9992 - auc_3: 0.9999 - loss: 0.0033 - precision_3: 0.9998 - val_accuracy: 0.9961 - val_auc_3: 0.9981 - val_loss: 0.0254 - val_precision_3: 0.9959\n",
      "Epoch 10/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 200ms/step - accuracy: 0.9992 - auc_3: 0.9997 - loss: 0.0056 - precision_3: 0.9988 - val_accuracy: 0.9961 - val_auc_3: 0.9983 - val_loss: 0.0248 - val_precision_3: 0.9959\n",
      "Epoch 11/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 202ms/step - accuracy: 0.9989 - auc_3: 0.9998 - loss: 0.0053 - precision_3: 0.9994 - val_accuracy: 0.9961 - val_auc_3: 0.9981 - val_loss: 0.0265 - val_precision_3: 0.9959\n",
      "Epoch 12/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 202ms/step - accuracy: 0.9996 - auc_3: 0.9998 - loss: 0.0051 - precision_3: 0.9993 - val_accuracy: 0.9964 - val_auc_3: 0.9983 - val_loss: 0.0241 - val_precision_3: 0.9959\n",
      "Epoch 13/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 202ms/step - accuracy: 0.9990 - auc_3: 0.9997 - loss: 0.0062 - precision_3: 0.9987 - val_accuracy: 0.9972 - val_auc_3: 0.9983 - val_loss: 0.0235 - val_precision_3: 0.9973\n",
      "Epoch 14/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 220ms/step - accuracy: 0.9995 - auc_3: 1.0000 - loss: 0.0020 - precision_3: 0.9998 - val_accuracy: 0.9972 - val_auc_3: 0.9983 - val_loss: 0.0242 - val_precision_3: 0.9973\n",
      "Epoch 15/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 204ms/step - accuracy: 0.9995 - auc_3: 0.9999 - loss: 0.0026 - precision_3: 0.9997 - val_accuracy: 0.9969 - val_auc_3: 0.9983 - val_loss: 0.0234 - val_precision_3: 0.9966\n",
      "Epoch 16/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 204ms/step - accuracy: 0.9994 - auc_3: 1.0000 - loss: 0.0017 - precision_3: 0.9996 - val_accuracy: 0.9966 - val_auc_3: 0.9983 - val_loss: 0.0237 - val_precision_3: 0.9959\n",
      "Epoch 17/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 203ms/step - accuracy: 0.9995 - auc_3: 0.9999 - loss: 0.0027 - precision_3: 0.9997 - val_accuracy: 0.9969 - val_auc_3: 0.9981 - val_loss: 0.0249 - val_precision_3: 0.9966\n",
      "Epoch 18/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 203ms/step - accuracy: 0.9996 - auc_3: 0.9999 - loss: 0.0027 - precision_3: 0.9997 - val_accuracy: 0.9972 - val_auc_3: 0.9983 - val_loss: 0.0235 - val_precision_3: 0.9966\n",
      "Epoch 19/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 203ms/step - accuracy: 0.9996 - auc_3: 1.0000 - loss: 0.0011 - precision_3: 0.9999 - val_accuracy: 0.9972 - val_auc_3: 0.9981 - val_loss: 0.0245 - val_precision_3: 0.9966\n",
      "Epoch 20/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 204ms/step - accuracy: 0.9996 - auc_3: 0.9999 - loss: 0.0024 - precision_3: 0.9998 - val_accuracy: 0.9972 - val_auc_3: 0.9983 - val_loss: 0.0233 - val_precision_3: 0.9966\n",
      "Epoch 21/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 212ms/step - accuracy: 0.9995 - auc_3: 0.9999 - loss: 0.0035 - precision_3: 0.9996 - val_accuracy: 0.9972 - val_auc_3: 0.9980 - val_loss: 0.0242 - val_precision_3: 0.9966\n",
      "Epoch 22/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 225ms/step - accuracy: 0.9995 - auc_3: 0.9998 - loss: 0.0055 - precision_3: 0.9991 - val_accuracy: 0.9966 - val_auc_3: 0.9980 - val_loss: 0.0259 - val_precision_3: 0.9966\n",
      "Epoch 23/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 209ms/step - accuracy: 0.9991 - auc_3: 1.0000 - loss: 0.0020 - precision_3: 0.9999 - val_accuracy: 0.9974 - val_auc_3: 0.9983 - val_loss: 0.0232 - val_precision_3: 0.9973\n",
      "Epoch 24/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 198ms/step - accuracy: 0.9994 - auc_3: 0.9997 - loss: 0.0045 - precision_3: 0.9991 - val_accuracy: 0.9974 - val_auc_3: 0.9981 - val_loss: 0.0232 - val_precision_3: 0.9973\n",
      "Epoch 25/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 198ms/step - accuracy: 0.9999 - auc_3: 1.0000 - loss: 0.0012 - precision_3: 0.9998 - val_accuracy: 0.9974 - val_auc_3: 0.9981 - val_loss: 0.0241 - val_precision_3: 0.9973\n",
      "Epoch 26/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 213ms/step - accuracy: 0.9999 - auc_3: 1.0000 - loss: 4.9698e-04 - precision_3: 1.0000 - val_accuracy: 0.9972 - val_auc_3: 0.9983 - val_loss: 0.0228 - val_precision_3: 0.9973\n",
      "Epoch 27/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 213ms/step - accuracy: 0.9997 - auc_3: 0.9999 - loss: 0.0024 - precision_3: 0.9997 - val_accuracy: 0.9972 - val_auc_3: 0.9983 - val_loss: 0.0223 - val_precision_3: 0.9973\n",
      "Epoch 28/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 202ms/step - accuracy: 0.9996 - auc_3: 1.0000 - loss: 0.0017 - precision_3: 0.9997 - val_accuracy: 0.9972 - val_auc_3: 0.9985 - val_loss: 0.0229 - val_precision_3: 0.9973\n",
      "Epoch 29/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 204ms/step - accuracy: 0.9999 - auc_3: 1.0000 - loss: 0.0011 - precision_3: 0.9998 - val_accuracy: 0.9972 - val_auc_3: 0.9981 - val_loss: 0.0249 - val_precision_3: 0.9973\n",
      "Epoch 30/30\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 225ms/step - accuracy: 0.9996 - auc_3: 1.0000 - loss: 0.0024 - precision_3: 0.9998 - val_accuracy: 0.9966 - val_auc_3: 0.9981 - val_loss: 0.0241 - val_precision_3: 0.9973\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=128, validation_split=0.2, callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "# Save Weights\n",
    "model.save_weights(\"../models/weights.weights.h5\")\n",
    "\n",
    "# Save Model Architecture\n",
    "with open(\"../models/model.json\", \"w\") as f:\n",
    "    f.write(model.to_json())\n",
    "\n",
    "print(\"Model Saved Successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
